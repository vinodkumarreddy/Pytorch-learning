{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMowEFygtaCmOAU/KyWZqVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinodkumarreddy/Pytorch-learning/blob/main/Pytorch_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Section is on how to create a tensor. We already know all the corresponding functions. Then he discusses on random seeds and how initializing them would mean that the sequence of number generated given a random seed is deterministic. Then he moves on to shapes and like functions"
      ],
      "metadata": {
        "id": "Xq-qGxi6LSQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "lzOboIHKLSBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.rand(size = (3,2))"
      ],
      "metadata": {
        "id": "_LSdTFSSLR_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_t = torch.ones_like(a_t)"
      ],
      "metadata": {
        "id": "rR0nz_BmLR9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t.shape, b_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnhZ4V27LR7B",
        "outputId": "5e204eda-3e10-4156-cba1-54d9ad7ab17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moves on to discuss how to convert standard python datatypes like list of lists etc into tensors using the torch.tensor function"
      ],
      "metadata": {
        "id": "SXxuF__XL7QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWQU9C4KLR4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next is on datatypes and type conversions. By default most tensors are of the type float32. We can change the tensor format by specifying the requisite format while creating the tensor or we can also type cast the tensor using the .to function."
      ],
      "metadata": {
        "id": "o7qLw6OUMGob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((3,2))"
      ],
      "metadata": {
        "id": "IZC9YrUaLR1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gxjVh15LRza",
        "outputId": "6db5d0a6-4acd-4e35-d2fe-80dec3bda3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.to(torch.int32).dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hy734kVLRw9",
        "outputId": "2a177ee9-3d7c-4892-d5db-cfc893ab3412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1,1], [2,1]]"
      ],
      "metadata": {
        "id": "AJXJitDRLRub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uAt2GIKLRr3",
        "outputId": "1e1a5686-6eac-4365-967f-3fafeac37d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1], [2, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.tensor(a)"
      ],
      "metadata": {
        "id": "ZnBLQ9_ILRpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CXT1yPLLQvM",
        "outputId": "f9e0c5af-7d12-4924-b54e-27ad64eb7b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the cases where the default data type if inferred from the data is when we are converting some existing python datatype to tensor. It seems like the data type is being inferref from the data."
      ],
      "metadata": {
        "id": "b4nQcKofMy2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1,1.1], [2.1,1.2]]"
      ],
      "metadata": {
        "id": "lskYQqf3LQsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(a).dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCKYylC9LQqF",
        "outputId": "3b30bdf7-9661-4cb3-8636-ed7559642ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bX0rRzCDNEar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generic math operations on tensors"
      ],
      "metadata": {
        "id": "y6D_PdKANHvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones((3,4))\n",
        "twos = ones*2\n",
        "threes = twos + ones\n",
        "fours = twos**2\n",
        "sqrts = twos**0.5"
      ],
      "metadata": {
        "id": "FNjpPROsNEXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu_DgT7UNEVM",
        "outputId": "b6487abf-13b9-424c-b37e-8d10a3cfce74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ggj6XsONES4",
        "outputId": "aae4364b-8c26-4a03-caa0-6544bffef827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTgeLGLyNEQe",
        "outputId": "d82374bf-780f-4be5-958b-9da372f1db25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fours"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTMk8QUqNEN9",
        "outputId": "cf996688-2f9e-45f7-9b37-b245ade2cab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 4., 4., 4.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [4., 4., 4., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqrts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqPxuDe5NELl",
        "outputId": "5a08d9d0-0551-4558-b842-313c12e5470d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4142, 1.4142, 1.4142, 1.4142],\n",
              "        [1.4142, 1.4142, 1.4142, 1.4142],\n",
              "        [1.4142, 1.4142, 1.4142, 1.4142]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally any operation with a scalar is broadcasted to the whole tensor. Similarly element wise operations occur when we are doing these operations between to tensors. There is also broadcasting in these cases as well"
      ],
      "metadata": {
        "id": "d6DnBhAcNgk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Double broadcasting test\n",
        "a = torch.ones(size = (3,1))\n",
        "b = torch.rand((1,2))\n",
        "a, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2BsmpOjNgSO",
        "outputId": "ff3ca439-ec6e-4fa0-af91-e806597dec26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [1.],\n",
              "         [1.]]),\n",
              " tensor([[0.0298, 0.9041]]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a*b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4s4SF16NEJI",
        "outputId": "d23564ea-36a6-4a6f-89e5-1ec103d8977d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0298, 0.9041],\n",
              "        [0.0298, 0.9041],\n",
              "        [0.0298, 0.9041]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are also many math operations supported by pytorch. Need to check if every operation allows for gradient calculations"
      ],
      "metadata": {
        "id": "VAOiJUPXOj4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "eTfk9jNKNEGx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing out various functions available in pytorch"
      ],
      "metadata": {
        "id": "7ZAhxgPvugvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.rand(size = (2,2)) * 10 - 5"
      ],
      "metadata": {
        "id": "C-YWpH8FNEEZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EByBMB4KuwQ_",
        "outputId": "231b344a-3c2c-4c4c-824a-d395e97555b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3697,  4.4144],\n",
              "        [-4.0055, -2.3486]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(a_t)"
      ],
      "metadata": {
        "id": "HgMGUI_JNEB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6953d6-0338-4df4-966d-e9fe9db4688c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3697, 4.4144],\n",
              "        [4.0055, 2.3486]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ceil(a_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ydOzzTfuviB",
        "outputId": "3c3050ab-0688-473a-8ff8-5035bcff2bdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  5.],\n",
              "        [-4., -2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0F0Q3EV_Milr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0687320d-4442-44f2-d593-44d32f1afcda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.,  4.],\n",
              "        [-5., -3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.floor(a_t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.clamp(a_t, -2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGo-sUtau3np",
        "outputId": "13c59550-acab-4d29-e8fb-f7627652e637"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3697,  2.0000],\n",
              "        [-2.0000, -2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6csRypWDu-S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "cmVXL2g5vFwq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math.pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHrByD9vvGlO",
        "outputId": "49cca273-c3d1-42ff-8016-400563035329"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.141592653589793"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_t = torch.tensor([math.pi/4, math.pi/3, math.pi/2, math.pi])"
      ],
      "metadata": {
        "id": "FQiWo4E6vB54"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sin(angle_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGcyZGA8vB2h",
        "outputId": "8ba52d8e-6f39-40a4-c7d6-f5384cc0f834"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7.0711e-01,  8.6603e-01,  1.0000e+00, -8.7423e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cos(angle_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tptqZFh5vB0M",
        "outputId": "8c064551-087d-410a-c37c-cb87fef7b243"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7.0711e-01,  5.0000e-01, -4.3711e-08, -1.0000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.asin(torch.sin(angle_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgSe5PkAvBx9",
        "outputId": "ee4ff12d-6052-4890-ef0c-923dbddbee8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7.8540e-01,  1.0472e+00,  1.5708e+00, -8.7423e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0f8M6vVvBvv",
        "outputId": "3458be04-c819-4e98-deab-2cdc77530722"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7854, 1.0472, 1.5708, 3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghio4S0DvBtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4LJNyo5vBrI",
        "outputId": "6ecd9126-ea1e-4df4-c5b7-49cd18ae0a0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d == e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9amiSMYDvBow",
        "outputId": "dbd03ea2-701a-4e2e-b040-45775d9d2386"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False],\n",
              "        [False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d >= e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olPF9-mSvBmF",
        "outputId": "b5a11a14-5d7b-4a38-e370-9990bb926135"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True],\n",
              "        [True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nhYtt19nyCcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max??"
      ],
      "metadata": {
        "id": "Xo7LxZ3tyCZL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.rand(size = (2,3,2))"
      ],
      "metadata": {
        "id": "y2G8A2N_yCVC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHf6ygHfyCSr",
        "outputId": "9c27304e-2a04-4afc-c76b-7be0d11c6390"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0660, 0.9148],\n",
              "         [0.6369, 0.0686],\n",
              "         [0.9092, 0.6599]],\n",
              "\n",
              "        [[0.0113, 0.7694],\n",
              "         [0.4297, 0.9270],\n",
              "         [0.5566, 0.8728]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(a_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liN6vhvEyCQJ",
        "outputId": "5e08eb96-dc75-4e19-8829-5ee48fab972e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9270)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(input = a_t, dim = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF1R4jDQyCNi",
        "outputId": "ccea554a-fbc4-41e1-c3d7-1d184084cde6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([[0.0660, 0.9148],\n",
              "        [0.6369, 0.9270],\n",
              "        [0.9092, 0.8728]]),\n",
              "indices=tensor([[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(input = a_t, dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUhNtRQxyCK9",
        "outputId": "0a2f44f0-ab26-48de-a48d-89aa20c1eeed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([[0.9092, 0.9148],\n",
              "        [0.5566, 0.9270]]),\n",
              "indices=tensor([[2, 0],\n",
              "        [2, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "80Eho4ZTvBjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case of converting the predicted values to corresponding class"
      ],
      "metadata": {
        "id": "QpoVQctky_Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = torch.rand(size = (100, 20))"
      ],
      "metadata": {
        "id": "J6Z1sfl8y-4c"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_class_probs, output_classes = torch.max(outputs, dim = 1)"
      ],
      "metadata": {
        "id": "t08YAvX0vBhD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_classes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELHA8NWxzOOt",
        "outputId": "c2141cc0-8589-423f-b88b-db9dbcf5e307"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(a_t, dim = 0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdjfsMX2zSmS",
        "outputId": "99d4184c-4d68-455c-be38-8a4f2515df56"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean??"
      ],
      "metadata": {
        "id": "4m5GxVkSzYi4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.std(a_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLeWbArYzl2U",
        "outputId": "03c8623c-7903-4198-d63e-67ab1d5dc83d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3494)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.prod(a_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omxWEyOLzly9",
        "outputId": "dc4f6ac5-ba59-4355-a6e3-29a7acc102f2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.6755e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lneTjxtzlw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning a tensor to another would not copy the tensor. Instead it just copies the pointer. We would need to explicitly use the clone method to copy a tensor. Clone also looks at the original autograd settings of the tensor. If the original has grad turned on then clone will also have it and any gradient will be propogated to the original while doing backward(). There is also the detach method. While just gets the tensor values without affecting the computational gradient. Does it create a clone?"
      ],
      "metadata": {
        "id": "y-6uDsCc3nF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(size = (3,4), requires_grad = True)"
      ],
      "metadata": {
        "id": "JH0iGN4GzluW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7aWsKhzlsA",
        "outputId": "62f2ccfd-f881-4a7e-89ff-8d950383cd2a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3308, 0.2392, 0.7425, 0.6823],\n",
              "        [0.3806, 0.0097, 0.3490, 0.1767],\n",
              "        [0.9397, 0.1434, 0.4187, 0.0665]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.detach()"
      ],
      "metadata": {
        "id": "-9j_Cgdnzlpu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert b is not a"
      ],
      "metadata": {
        "id": "fPP7MSy0zlm8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQGMgQOWzlke",
        "outputId": "93c4ee07-9bc6-4ae8-bb12-b19febdb6eac"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139525899083328"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugMMd6iLzlh1",
        "outputId": "de558b72-4911-4fc5-a247-7896e5650e94"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139525901405856"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b[0][1] = 1"
      ],
      "metadata": {
        "id": "tthLr6VCzbRN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myqiupob5Sp3",
        "outputId": "f17ade13-7d84-4ab6-b993-599eab468b5d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3308, 1.0000, 0.7425, 0.6823],\n",
              "        [0.3806, 0.0097, 0.3490, 0.1767],\n",
              "        [0.9397, 0.1434, 0.4187, 0.0665]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like detach doesn't copy the contents for the new tensor. It should be a better idea to first detach and then do a clone so that there is no linkage between the newly created tensor and the original tensor"
      ],
      "metadata": {
        "id": "PLBMNdbl5aek"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cv6PM0tz5-PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"gpu\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sELB6gJ75-L5",
        "outputId": "911afc8c-5689-4760-d959-b0c7cb28ba18"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaiFiURi5-G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape editing for tensors"
      ],
      "metadata": {
        "id": "SbgCwHuQ7gZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(size = (3, 32, 32))"
      ],
      "metadata": {
        "id": "98y5_3q75-Ej"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7G-qWTy5Z5b",
        "outputId": "34b57bfd-016a-4d14-bb44-8780614a8a77"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.unsqueeze(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nZT6GbV5Z1_",
        "outputId": "a8141da3-aaee-49c3-8958-ff0ab55275b2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.unsqueeze(1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDTIxuuc5Z0a",
        "outputId": "4213d498-dae0-49f8-917b-c4c424bd6b8d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.unsqueeze(2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQBUnDJp5ZyB",
        "outputId": "57ff107c-d9d3-4f16-cb80-0a56054f6947"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 1, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(size = (1, 20))"
      ],
      "metadata": {
        "id": "XRoqNwEw5Zvq"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JghVygl5ZtJ",
        "outputId": "ecc304f2-b86d-4361-ce4a-2b092a6d1e14"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8bFd1315Zqn",
        "outputId": "016f49ef-16a0-4a14-ec69-ee1224c27140"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLTDv7Gp5Zoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeR0ZiYi5UsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a linear regression model using whatever we have learnt till now."
      ],
      "metadata": {
        "id": "gue7DbQ--S0g"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the synthetic data"
      ],
      "metadata": {
        "id": "Tlw42m4A_Wqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "869KWKyke_u8"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = [1, 2, 3]\n",
        "b = [4]"
      ],
      "metadata": {
        "id": "RpsK_P0J_U4t"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_t = torch.tensor(W, dtype = torch.float32)\n",
        "b_t = torch.tensor(b, dtype = torch.float32)"
      ],
      "metadata": {
        "id": "4YHsVOek_hSP"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_t.shape, b_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQlMIOcrfh-O",
        "outputId": "78656908-4184-41cb-b89b-cd42e7011cd6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_t = W_t.reshape(3, 1)"
      ],
      "metadata": {
        "id": "wNtHdVGkfvBi"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t = torch.rand(size = (100, 3)) * 10 - 5"
      ],
      "metadata": {
        "id": "z04buwEV_2mP"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNIlDMG-fJz5",
        "outputId": "56c08ac1-2fef-495c-a34d-ba032b405de9"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coeff = torch.randint(low = 0, high = 100, size = (100,3))"
      ],
      "metadata": {
        "id": "usAizwJwgJ4v"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t = X_t * coeff"
      ],
      "metadata": {
        "id": "KYIQpO6kgrWL"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = 0\n",
        "std = 0.5"
      ],
      "metadata": {
        "id": "4bd30b9SgCpe"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(size = (100, 1))"
      ],
      "metadata": {
        "id": "qvYumkTbg2F1"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = torch.normal(ones*mean, ones*std)"
      ],
      "metadata": {
        "id": "f6zrE3fsf_Uy"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_t = X_t @ W_t + b_t + errors"
      ],
      "metadata": {
        "id": "Ylh5whz1e9Vm"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfpIZ9TifHqO",
        "outputId": "a1b5fa70-6c67-4d9e-d70f-55e0c6857c78"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_t.shape, y_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5EFxICof6LB",
        "outputId": "45778601-21f3-45dc-affa-3a3f928b8af6"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 3]), torch.Size([100, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = X_t.mean(dim = 0)\n",
        "std = torch.std(X_t, dim = 0)"
      ],
      "metadata": {
        "id": "P25qQuP5_Oq-"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t.shape, mean.shape, std.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGDcNgv3laBV",
        "outputId": "02658a2b-1fd2-48ab-e590-dd1260d3daa4"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 3]), torch.Size([3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_norm = (X_t - mean)/std"
      ],
      "metadata": {
        "id": "RlwTgLX1lZ93"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7dw-0le7lbhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pW = torch.rand(size = (3,1), requires_grad = True)\n",
        "pb = torch.rand(size = (1,), requires_grad = True)"
      ],
      "metadata": {
        "id": "Y4Mv2ddW-SvL"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = X_t @ pW + pb\n",
        "loss = torch.sum((y_t - y_pred)**2)/y_t.shape[0]\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "m3qxDk8zluQ0"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pW.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMe6K11vl5Q-",
        "outputId": "5dd752b0-1c1f-4491-ca5b-20291eb19217"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -50654.1094],\n",
              "        [ -82741.4141],\n",
              "        [-128655.4375]])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pW.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAlAobZel65x",
        "outputId": "57894744-67d0-4025-b809-fbd7cda576cd"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pW.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFO26nKMl8Xl",
        "outputId": "394be21c-151e-4e18-ba75-3c91a0aba53b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "lr = 0.01\n",
        "for epoch in range(epochs):\n",
        "  y_pred = X_t_norm @ pW + pb\n",
        "  loss = torch.sum((y_t - y_pred)**2)/y_t.shape[0]\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    pW -= lr*pW.grad\n",
        "    pb -= lr*pb.grad\n",
        "  print(f\"Epoch - {epoch + 1}, loss - {loss.item()}\")\n",
        "  # print(f\"Gradient of pW - {pW.detach()}\")\n",
        "  # print(f\"Gradient of pb - {pb.detach()}\")\n",
        "  # print(f\"pW - {pW}\")\n",
        "  # print(f\"pb - {pb}\")\n",
        "  # print(\"*\"*100)\n",
        "  # print(\"*\"*100)\n",
        "  pW.grad.zero_()\n",
        "  pb.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlbQXpYh-Ss_",
        "outputId": "80b7e0e0-4894-4977-c7f2-2931583f1fc8"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 1, loss - 116796.8984375\n",
            "Epoch - 2, loss - 111769.3125\n",
            "Epoch - 3, loss - 106958.5625\n",
            "Epoch - 4, loss - 102355.296875\n",
            "Epoch - 5, loss - 97950.546875\n",
            "Epoch - 6, loss - 93735.75\n",
            "Epoch - 7, loss - 89702.65625\n",
            "Epoch - 8, loss - 85843.4765625\n",
            "Epoch - 9, loss - 82150.65625\n",
            "Epoch - 10, loss - 78617.03125\n",
            "Epoch - 11, loss - 75235.6953125\n",
            "Epoch - 12, loss - 72000.09375\n",
            "Epoch - 13, loss - 68903.9375\n",
            "Epoch - 14, loss - 65941.203125\n",
            "Epoch - 15, loss - 63106.11328125\n",
            "Epoch - 16, loss - 60393.171875\n",
            "Epoch - 17, loss - 57797.1015625\n",
            "Epoch - 18, loss - 55312.859375\n",
            "Epoch - 19, loss - 52935.60546875\n",
            "Epoch - 20, loss - 50660.73828125\n",
            "Epoch - 21, loss - 48483.8515625\n",
            "Epoch - 22, loss - 46400.69921875\n",
            "Epoch - 23, loss - 44407.23046875\n",
            "Epoch - 24, loss - 42499.578125\n",
            "Epoch - 25, loss - 40674.0625\n",
            "Epoch - 26, loss - 38927.11328125\n",
            "Epoch - 27, loss - 37255.36328125\n",
            "Epoch - 28, loss - 35655.55078125\n",
            "Epoch - 29, loss - 34124.578125\n",
            "Epoch - 30, loss - 32659.494140625\n",
            "Epoch - 31, loss - 31257.4296875\n",
            "Epoch - 32, loss - 29915.69921875\n",
            "Epoch - 33, loss - 28631.677734375\n",
            "Epoch - 34, loss - 27402.8828125\n",
            "Epoch - 35, loss - 26226.9453125\n",
            "Epoch - 36, loss - 25101.572265625\n",
            "Epoch - 37, loss - 24024.591796875\n",
            "Epoch - 38, loss - 22993.921875\n",
            "Epoch - 39, loss - 22007.5625\n",
            "Epoch - 40, loss - 21063.60546875\n",
            "Epoch - 41, loss - 20160.22265625\n",
            "Epoch - 42, loss - 19295.66796875\n",
            "Epoch - 43, loss - 18468.267578125\n",
            "Epoch - 44, loss - 17676.4296875\n",
            "Epoch - 45, loss - 16918.615234375\n",
            "Epoch - 46, loss - 16193.3564453125\n",
            "Epoch - 47, loss - 15499.2548828125\n",
            "Epoch - 48, loss - 14834.97265625\n",
            "Epoch - 49, loss - 14199.224609375\n",
            "Epoch - 50, loss - 13590.7822265625\n",
            "Epoch - 51, loss - 13008.462890625\n",
            "Epoch - 52, loss - 12451.150390625\n",
            "Epoch - 53, loss - 11917.7685546875\n",
            "Epoch - 54, loss - 11407.2841796875\n",
            "Epoch - 55, loss - 10918.7158203125\n",
            "Epoch - 56, loss - 10451.119140625\n",
            "Epoch - 57, loss - 10003.5927734375\n",
            "Epoch - 58, loss - 9575.271484375\n",
            "Epoch - 59, loss - 9165.3291015625\n",
            "Epoch - 60, loss - 8772.9765625\n",
            "Epoch - 61, loss - 8397.455078125\n",
            "Epoch - 62, loss - 8038.04248046875\n",
            "Epoch - 63, loss - 7694.056640625\n",
            "Epoch - 64, loss - 7364.822265625\n",
            "Epoch - 65, loss - 7049.7060546875\n",
            "Epoch - 66, loss - 6748.103515625\n",
            "Epoch - 67, loss - 6459.42919921875\n",
            "Epoch - 68, loss - 6183.13671875\n",
            "Epoch - 69, loss - 5918.685546875\n",
            "Epoch - 70, loss - 5665.57080078125\n",
            "Epoch - 71, loss - 5423.30810546875\n",
            "Epoch - 72, loss - 5191.42919921875\n",
            "Epoch - 73, loss - 4969.482421875\n",
            "Epoch - 74, loss - 4757.048828125\n",
            "Epoch - 75, loss - 4553.716796875\n",
            "Epoch - 76, loss - 4359.095703125\n",
            "Epoch - 77, loss - 4172.81201171875\n",
            "Epoch - 78, loss - 3994.507568359375\n",
            "Epoch - 79, loss - 3823.8388671875\n",
            "Epoch - 80, loss - 3660.479736328125\n",
            "Epoch - 81, loss - 3504.116455078125\n",
            "Epoch - 82, loss - 3354.446533203125\n",
            "Epoch - 83, loss - 3211.185546875\n",
            "Epoch - 84, loss - 3074.056884765625\n",
            "Epoch - 85, loss - 2942.7978515625\n",
            "Epoch - 86, loss - 2817.1572265625\n",
            "Epoch - 87, loss - 2696.892578125\n",
            "Epoch - 88, loss - 2581.775390625\n",
            "Epoch - 89, loss - 2471.581787109375\n",
            "Epoch - 90, loss - 2366.1044921875\n",
            "Epoch - 91, loss - 2265.1376953125\n",
            "Epoch - 92, loss - 2168.490234375\n",
            "Epoch - 93, loss - 2075.976318359375\n",
            "Epoch - 94, loss - 1987.42041015625\n",
            "Epoch - 95, loss - 1902.6480712890625\n",
            "Epoch - 96, loss - 1821.5029296875\n",
            "Epoch - 97, loss - 1743.825927734375\n",
            "Epoch - 98, loss - 1669.4708251953125\n",
            "Epoch - 99, loss - 1598.29345703125\n",
            "Epoch - 100, loss - 1530.1572265625\n",
            "Epoch - 101, loss - 1464.93505859375\n",
            "Epoch - 102, loss - 1402.498779296875\n",
            "Epoch - 103, loss - 1342.7303466796875\n",
            "Epoch - 104, loss - 1285.51611328125\n",
            "Epoch - 105, loss - 1230.7452392578125\n",
            "Epoch - 106, loss - 1178.31298828125\n",
            "Epoch - 107, loss - 1128.120361328125\n",
            "Epoch - 108, loss - 1080.0718994140625\n",
            "Epoch - 109, loss - 1034.076171875\n",
            "Epoch - 110, loss - 990.0435180664062\n",
            "Epoch - 111, loss - 947.8904418945312\n",
            "Epoch - 112, loss - 907.536376953125\n",
            "Epoch - 113, loss - 868.9044799804688\n",
            "Epoch - 114, loss - 831.92138671875\n",
            "Epoch - 115, loss - 796.5167846679688\n",
            "Epoch - 116, loss - 762.623779296875\n",
            "Epoch - 117, loss - 730.1766967773438\n",
            "Epoch - 118, loss - 699.1140747070312\n",
            "Epoch - 119, loss - 669.3760375976562\n",
            "Epoch - 120, loss - 640.90673828125\n",
            "Epoch - 121, loss - 613.6514282226562\n",
            "Epoch - 122, loss - 587.5584716796875\n",
            "Epoch - 123, loss - 562.5783081054688\n",
            "Epoch - 124, loss - 538.6620483398438\n",
            "Epoch - 125, loss - 515.7667846679688\n",
            "Epoch - 126, loss - 493.8476867675781\n",
            "Epoch - 127, loss - 472.86285400390625\n",
            "Epoch - 128, loss - 452.7716064453125\n",
            "Epoch - 129, loss - 433.5369567871094\n",
            "Epoch - 130, loss - 415.1219787597656\n",
            "Epoch - 131, loss - 397.49090576171875\n",
            "Epoch - 132, loss - 380.61151123046875\n",
            "Epoch - 133, loss - 364.4512939453125\n",
            "Epoch - 134, loss - 348.979248046875\n",
            "Epoch - 135, loss - 334.1653137207031\n",
            "Epoch - 136, loss - 319.9833068847656\n",
            "Epoch - 137, loss - 306.4037780761719\n",
            "Epoch - 138, loss - 293.4031982421875\n",
            "Epoch - 139, loss - 280.9559326171875\n",
            "Epoch - 140, loss - 269.03826904296875\n",
            "Epoch - 141, loss - 257.62847900390625\n",
            "Epoch - 142, loss - 246.70327758789062\n",
            "Epoch - 143, loss - 236.24374389648438\n",
            "Epoch - 144, loss - 226.22898864746094\n",
            "Epoch - 145, loss - 216.6403350830078\n",
            "Epoch - 146, loss - 207.45970153808594\n",
            "Epoch - 147, loss - 198.66957092285156\n",
            "Epoch - 148, loss - 190.25328063964844\n",
            "Epoch - 149, loss - 182.19496154785156\n",
            "Epoch - 150, loss - 174.4794921875\n",
            "Epoch - 151, loss - 167.09222412109375\n",
            "Epoch - 152, loss - 160.0177459716797\n",
            "Epoch - 153, loss - 153.24485778808594\n",
            "Epoch - 154, loss - 146.75975036621094\n",
            "Epoch - 155, loss - 140.5500030517578\n",
            "Epoch - 156, loss - 134.6046142578125\n",
            "Epoch - 157, loss - 128.91156005859375\n",
            "Epoch - 158, loss - 123.46014404296875\n",
            "Epoch - 159, loss - 118.24043273925781\n",
            "Epoch - 160, loss - 113.24246978759766\n",
            "Epoch - 161, loss - 108.45703887939453\n",
            "Epoch - 162, loss - 103.87444305419922\n",
            "Epoch - 163, loss - 99.48664855957031\n",
            "Epoch - 164, loss - 95.28506469726562\n",
            "Epoch - 165, loss - 91.26213073730469\n",
            "Epoch - 166, loss - 87.40974426269531\n",
            "Epoch - 167, loss - 83.72087860107422\n",
            "Epoch - 168, loss - 80.18839263916016\n",
            "Epoch - 169, loss - 76.80573272705078\n",
            "Epoch - 170, loss - 73.56681823730469\n",
            "Epoch - 171, loss - 70.46501922607422\n",
            "Epoch - 172, loss - 67.49531555175781\n",
            "Epoch - 173, loss - 64.65137481689453\n",
            "Epoch - 174, loss - 61.927913665771484\n",
            "Epoch - 175, loss - 59.32052230834961\n",
            "Epoch - 176, loss - 56.823394775390625\n",
            "Epoch - 177, loss - 54.43214416503906\n",
            "Epoch - 178, loss - 52.141902923583984\n",
            "Epoch - 179, loss - 49.94886779785156\n",
            "Epoch - 180, loss - 47.848854064941406\n",
            "Epoch - 181, loss - 45.837677001953125\n",
            "Epoch - 182, loss - 43.911964416503906\n",
            "Epoch - 183, loss - 42.06801223754883\n",
            "Epoch - 184, loss - 40.30189514160156\n",
            "Epoch - 185, loss - 38.61076354980469\n",
            "Epoch - 186, loss - 36.991146087646484\n",
            "Epoch - 187, loss - 35.44008255004883\n",
            "Epoch - 188, loss - 33.954559326171875\n",
            "Epoch - 189, loss - 32.53201675415039\n",
            "Epoch - 190, loss - 31.169692993164062\n",
            "Epoch - 191, loss - 29.865131378173828\n",
            "Epoch - 192, loss - 28.615800857543945\n",
            "Epoch - 193, loss - 27.419363021850586\n",
            "Epoch - 194, loss - 26.273601531982422\n",
            "Epoch - 195, loss - 25.176227569580078\n",
            "Epoch - 196, loss - 24.12540054321289\n",
            "Epoch - 197, loss - 23.118995666503906\n",
            "Epoch - 198, loss - 22.15530014038086\n",
            "Epoch - 199, loss - 21.232275009155273\n",
            "Epoch - 200, loss - 20.348276138305664\n",
            "Epoch - 201, loss - 19.501718521118164\n",
            "Epoch - 202, loss - 18.690893173217773\n",
            "Epoch - 203, loss - 17.914289474487305\n",
            "Epoch - 204, loss - 17.170503616333008\n",
            "Epoch - 205, loss - 16.458152770996094\n",
            "Epoch - 206, loss - 15.775973320007324\n",
            "Epoch - 207, loss - 15.122852325439453\n",
            "Epoch - 208, loss - 14.496882438659668\n",
            "Epoch - 209, loss - 13.897552490234375\n",
            "Epoch - 210, loss - 13.323653221130371\n",
            "Epoch - 211, loss - 12.773998260498047\n",
            "Epoch - 212, loss - 12.247370719909668\n",
            "Epoch - 213, loss - 11.74321174621582\n",
            "Epoch - 214, loss - 11.260141372680664\n",
            "Epoch - 215, loss - 10.79748821258545\n",
            "Epoch - 216, loss - 10.354377746582031\n",
            "Epoch - 217, loss - 9.930023193359375\n",
            "Epoch - 218, loss - 9.523667335510254\n",
            "Epoch - 219, loss - 9.134401321411133\n",
            "Epoch - 220, loss - 8.761496543884277\n",
            "Epoch - 221, loss - 8.404285430908203\n",
            "Epoch - 222, loss - 8.062207221984863\n",
            "Epoch - 223, loss - 7.73464298248291\n",
            "Epoch - 224, loss - 7.420831680297852\n",
            "Epoch - 225, loss - 7.1201934814453125\n",
            "Epoch - 226, loss - 6.832339286804199\n",
            "Epoch - 227, loss - 6.556573390960693\n",
            "Epoch - 228, loss - 6.292399883270264\n",
            "Epoch - 229, loss - 6.039440155029297\n",
            "Epoch - 230, loss - 5.797119617462158\n",
            "Epoch - 231, loss - 5.5650200843811035\n",
            "Epoch - 232, loss - 5.3427324295043945\n",
            "Epoch - 233, loss - 5.129737377166748\n",
            "Epoch - 234, loss - 4.9257636070251465\n",
            "Epoch - 235, loss - 4.730384349822998\n",
            "Epoch - 236, loss - 4.543153762817383\n",
            "Epoch - 237, loss - 4.363840103149414\n",
            "Epoch - 238, loss - 4.192154884338379\n",
            "Epoch - 239, loss - 4.027624130249023\n",
            "Epoch - 240, loss - 3.870009183883667\n",
            "Epoch - 241, loss - 3.719036340713501\n",
            "Epoch - 242, loss - 3.5744235515594482\n",
            "Epoch - 243, loss - 3.4359304904937744\n",
            "Epoch - 244, loss - 3.303203821182251\n",
            "Epoch - 245, loss - 3.176129102706909\n",
            "Epoch - 246, loss - 3.0543413162231445\n",
            "Epoch - 247, loss - 2.937736749649048\n",
            "Epoch - 248, loss - 2.826029062271118\n",
            "Epoch - 249, loss - 2.719017744064331\n",
            "Epoch - 250, loss - 2.6165523529052734\n",
            "Epoch - 251, loss - 2.518350839614868\n",
            "Epoch - 252, loss - 2.424222707748413\n",
            "Epoch - 253, loss - 2.3340959548950195\n",
            "Epoch - 254, loss - 2.2477049827575684\n",
            "Epoch - 255, loss - 2.1649904251098633\n",
            "Epoch - 256, loss - 2.0857362747192383\n",
            "Epoch - 257, loss - 2.0098705291748047\n",
            "Epoch - 258, loss - 1.9371474981307983\n",
            "Epoch - 259, loss - 1.8675010204315186\n",
            "Epoch - 260, loss - 1.8007521629333496\n",
            "Epoch - 261, loss - 1.7368724346160889\n",
            "Epoch - 262, loss - 1.6755650043487549\n",
            "Epoch - 263, loss - 1.6168879270553589\n",
            "Epoch - 264, loss - 1.560692548751831\n",
            "Epoch - 265, loss - 1.5068615674972534\n",
            "Epoch - 266, loss - 1.455288290977478\n",
            "Epoch - 267, loss - 1.4059122800827026\n",
            "Epoch - 268, loss - 1.3585437536239624\n",
            "Epoch - 269, loss - 1.3131729364395142\n",
            "Epoch - 270, loss - 1.2697607278823853\n",
            "Epoch - 271, loss - 1.2281293869018555\n",
            "Epoch - 272, loss - 1.1882144212722778\n",
            "Epoch - 273, loss - 1.1500400304794312\n",
            "Epoch - 274, loss - 1.113447666168213\n",
            "Epoch - 275, loss - 1.0783531665802002\n",
            "Epoch - 276, loss - 1.0447628498077393\n",
            "Epoch - 277, loss - 1.0125564336776733\n",
            "Epoch - 278, loss - 0.981723427772522\n",
            "Epoch - 279, loss - 0.9521622657775879\n",
            "Epoch - 280, loss - 0.9238384366035461\n",
            "Epoch - 281, loss - 0.8966999053955078\n",
            "Epoch - 282, loss - 0.870727002620697\n",
            "Epoch - 283, loss - 0.8457909226417542\n",
            "Epoch - 284, loss - 0.8219083547592163\n",
            "Epoch - 285, loss - 0.7990573048591614\n",
            "Epoch - 286, loss - 0.777120053768158\n",
            "Epoch - 287, loss - 0.756147027015686\n",
            "Epoch - 288, loss - 0.7360151410102844\n",
            "Epoch - 289, loss - 0.7167633771896362\n",
            "Epoch - 290, loss - 0.6983122825622559\n",
            "Epoch - 291, loss - 0.6806187629699707\n",
            "Epoch - 292, loss - 0.66365647315979\n",
            "Epoch - 293, loss - 0.6474403142929077\n",
            "Epoch - 294, loss - 0.6318939328193665\n",
            "Epoch - 295, loss - 0.6169998645782471\n",
            "Epoch - 296, loss - 0.602709949016571\n",
            "Epoch - 297, loss - 0.5890177488327026\n",
            "Epoch - 298, loss - 0.5758955478668213\n",
            "Epoch - 299, loss - 0.5633237361907959\n",
            "Epoch - 300, loss - 0.5513021349906921\n",
            "Epoch - 301, loss - 0.5397509932518005\n",
            "Epoch - 302, loss - 0.5286829471588135\n",
            "Epoch - 303, loss - 0.518093466758728\n",
            "Epoch - 304, loss - 0.507927656173706\n",
            "Epoch - 305, loss - 0.4982073903083801\n",
            "Epoch - 306, loss - 0.48891448974609375\n",
            "Epoch - 307, loss - 0.48000332713127136\n",
            "Epoch - 308, loss - 0.47143810987472534\n",
            "Epoch - 309, loss - 0.4632347524166107\n",
            "Epoch - 310, loss - 0.45536717772483826\n",
            "Epoch - 311, loss - 0.4478309154510498\n",
            "Epoch - 312, loss - 0.44063127040863037\n",
            "Epoch - 313, loss - 0.4337216913700104\n",
            "Epoch - 314, loss - 0.4270901381969452\n",
            "Epoch - 315, loss - 0.42074325680732727\n",
            "Epoch - 316, loss - 0.41465163230895996\n",
            "Epoch - 317, loss - 0.40881866216659546\n",
            "Epoch - 318, loss - 0.403228759765625\n",
            "Epoch - 319, loss - 0.3978736102581024\n",
            "Epoch - 320, loss - 0.3927454650402069\n",
            "Epoch - 321, loss - 0.38783302903175354\n",
            "Epoch - 322, loss - 0.383122980594635\n",
            "Epoch - 323, loss - 0.37861043214797974\n",
            "Epoch - 324, loss - 0.37428489327430725\n",
            "Epoch - 325, loss - 0.3701367974281311\n",
            "Epoch - 326, loss - 0.3661636710166931\n",
            "Epoch - 327, loss - 0.36234936118125916\n",
            "Epoch - 328, loss - 0.35871583223342896\n",
            "Epoch - 329, loss - 0.3552260994911194\n",
            "Epoch - 330, loss - 0.35186251997947693\n",
            "Epoch - 331, loss - 0.34865012764930725\n",
            "Epoch - 332, loss - 0.34558331966400146\n",
            "Epoch - 333, loss - 0.34262344241142273\n",
            "Epoch - 334, loss - 0.33980247378349304\n",
            "Epoch - 335, loss - 0.3370940685272217\n",
            "Epoch - 336, loss - 0.334494948387146\n",
            "Epoch - 337, loss - 0.3320073187351227\n",
            "Epoch - 338, loss - 0.32961976528167725\n",
            "Epoch - 339, loss - 0.3273356556892395\n",
            "Epoch - 340, loss - 0.32514098286628723\n",
            "Epoch - 341, loss - 0.32304468750953674\n",
            "Epoch - 342, loss - 0.32102489471435547\n",
            "Epoch - 343, loss - 0.31911009550094604\n",
            "Epoch - 344, loss - 0.31725606322288513\n",
            "Epoch - 345, loss - 0.3154856562614441\n",
            "Epoch - 346, loss - 0.313780277967453\n",
            "Epoch - 347, loss - 0.3121612071990967\n",
            "Epoch - 348, loss - 0.3105996251106262\n",
            "Epoch - 349, loss - 0.3091108500957489\n",
            "Epoch - 350, loss - 0.30767086148262024\n",
            "Epoch - 351, loss - 0.3062988221645355\n",
            "Epoch - 352, loss - 0.30498412251472473\n",
            "Epoch - 353, loss - 0.30372145771980286\n",
            "Epoch - 354, loss - 0.30251798033714294\n",
            "Epoch - 355, loss - 0.30135661363601685\n",
            "Epoch - 356, loss - 0.3002503216266632\n",
            "Epoch - 357, loss - 0.299191951751709\n",
            "Epoch - 358, loss - 0.2981754243373871\n",
            "Epoch - 359, loss - 0.2971917688846588\n",
            "Epoch - 360, loss - 0.2962616980075836\n",
            "Epoch - 361, loss - 0.29535725712776184\n",
            "Epoch - 362, loss - 0.29449358582496643\n",
            "Epoch - 363, loss - 0.29366499185562134\n",
            "Epoch - 364, loss - 0.2928713858127594\n",
            "Epoch - 365, loss - 0.2921120822429657\n",
            "Epoch - 366, loss - 0.2913873493671417\n",
            "Epoch - 367, loss - 0.29069221019744873\n",
            "Epoch - 368, loss - 0.29002484679222107\n",
            "Epoch - 369, loss - 0.2893858253955841\n",
            "Epoch - 370, loss - 0.2887651026248932\n",
            "Epoch - 371, loss - 0.28817716240882874\n",
            "Epoch - 372, loss - 0.2876109778881073\n",
            "Epoch - 373, loss - 0.28707560896873474\n",
            "Epoch - 374, loss - 0.2865607440471649\n",
            "Epoch - 375, loss - 0.28606051206588745\n",
            "Epoch - 376, loss - 0.28557658195495605\n",
            "Epoch - 377, loss - 0.28512418270111084\n",
            "Epoch - 378, loss - 0.2846863567829132\n",
            "Epoch - 379, loss - 0.2842658758163452\n",
            "Epoch - 380, loss - 0.2838629186153412\n",
            "Epoch - 381, loss - 0.2834799885749817\n",
            "Epoch - 382, loss - 0.2831064760684967\n",
            "Epoch - 383, loss - 0.28275835514068604\n",
            "Epoch - 384, loss - 0.28240883350372314\n",
            "Epoch - 385, loss - 0.28208333253860474\n",
            "Epoch - 386, loss - 0.28177720308303833\n",
            "Epoch - 387, loss - 0.28148236870765686\n",
            "Epoch - 388, loss - 0.28119635581970215\n",
            "Epoch - 389, loss - 0.2809235751628876\n",
            "Epoch - 390, loss - 0.28066113591194153\n",
            "Epoch - 391, loss - 0.28040215373039246\n",
            "Epoch - 392, loss - 0.2801608443260193\n",
            "Epoch - 393, loss - 0.27992966771125793\n",
            "Epoch - 394, loss - 0.2797095775604248\n",
            "Epoch - 395, loss - 0.279491126537323\n",
            "Epoch - 396, loss - 0.2792956233024597\n",
            "Epoch - 397, loss - 0.27910488843917847\n",
            "Epoch - 398, loss - 0.278909295797348\n",
            "Epoch - 399, loss - 0.2787306010723114\n",
            "Epoch - 400, loss - 0.2785613536834717\n",
            "Epoch - 401, loss - 0.27839353680610657\n",
            "Epoch - 402, loss - 0.27823635935783386\n",
            "Epoch - 403, loss - 0.27808302640914917\n",
            "Epoch - 404, loss - 0.27793729305267334\n",
            "Epoch - 405, loss - 0.2778012156486511\n",
            "Epoch - 406, loss - 0.2776656150817871\n",
            "Epoch - 407, loss - 0.2775370180606842\n",
            "Epoch - 408, loss - 0.27741605043411255\n",
            "Epoch - 409, loss - 0.27729594707489014\n",
            "Epoch - 410, loss - 0.27718451619148254\n",
            "Epoch - 411, loss - 0.27707481384277344\n",
            "Epoch - 412, loss - 0.27697089314460754\n",
            "Epoch - 413, loss - 0.27687156200408936\n",
            "Epoch - 414, loss - 0.2767772674560547\n",
            "Epoch - 415, loss - 0.2766804099082947\n",
            "Epoch - 416, loss - 0.27659568190574646\n",
            "Epoch - 417, loss - 0.2765132486820221\n",
            "Epoch - 418, loss - 0.2764298617839813\n",
            "Epoch - 419, loss - 0.27634769678115845\n",
            "Epoch - 420, loss - 0.2762768864631653\n",
            "Epoch - 421, loss - 0.2762111723423004\n",
            "Epoch - 422, loss - 0.27614203095436096\n",
            "Epoch - 423, loss - 0.27607327699661255\n",
            "Epoch - 424, loss - 0.27601078152656555\n",
            "Epoch - 425, loss - 0.2759469747543335\n",
            "Epoch - 426, loss - 0.27589261531829834\n",
            "Epoch - 427, loss - 0.2758418321609497\n",
            "Epoch - 428, loss - 0.27578213810920715\n",
            "Epoch - 429, loss - 0.27573323249816895\n",
            "Epoch - 430, loss - 0.27567949891090393\n",
            "Epoch - 431, loss - 0.2756373882293701\n",
            "Epoch - 432, loss - 0.27558767795562744\n",
            "Epoch - 433, loss - 0.275547057390213\n",
            "Epoch - 434, loss - 0.27550211548805237\n",
            "Epoch - 435, loss - 0.27546682953834534\n",
            "Epoch - 436, loss - 0.275429904460907\n",
            "Epoch - 437, loss - 0.27539610862731934\n",
            "Epoch - 438, loss - 0.2753645181655884\n",
            "Epoch - 439, loss - 0.2753198742866516\n",
            "Epoch - 440, loss - 0.27529075741767883\n",
            "Epoch - 441, loss - 0.2752602696418762\n",
            "Epoch - 442, loss - 0.2752339243888855\n",
            "Epoch - 443, loss - 0.2752056121826172\n",
            "Epoch - 444, loss - 0.2751784026622772\n",
            "Epoch - 445, loss - 0.2751536965370178\n",
            "Epoch - 446, loss - 0.2751256823539734\n",
            "Epoch - 447, loss - 0.27510201930999756\n",
            "Epoch - 448, loss - 0.2750808596611023\n",
            "Epoch - 449, loss - 0.2750573754310608\n",
            "Epoch - 450, loss - 0.27503499388694763\n",
            "Epoch - 451, loss - 0.27501529455184937\n",
            "Epoch - 452, loss - 0.2749945819377899\n",
            "Epoch - 453, loss - 0.2749735414981842\n",
            "Epoch - 454, loss - 0.27496299147605896\n",
            "Epoch - 455, loss - 0.274944007396698\n",
            "Epoch - 456, loss - 0.2749241888523102\n",
            "Epoch - 457, loss - 0.27490735054016113\n",
            "Epoch - 458, loss - 0.2748953402042389\n",
            "Epoch - 459, loss - 0.2748827040195465\n",
            "Epoch - 460, loss - 0.27486634254455566\n",
            "Epoch - 461, loss - 0.27485498785972595\n",
            "Epoch - 462, loss - 0.2748459577560425\n",
            "Epoch - 463, loss - 0.2748304307460785\n",
            "Epoch - 464, loss - 0.2748182713985443\n",
            "Epoch - 465, loss - 0.2748069763183594\n",
            "Epoch - 466, loss - 0.2747962474822998\n",
            "Epoch - 467, loss - 0.2747822701931\n",
            "Epoch - 468, loss - 0.2747713625431061\n",
            "Epoch - 469, loss - 0.2747642993927002\n",
            "Epoch - 470, loss - 0.2747594118118286\n",
            "Epoch - 471, loss - 0.2747548818588257\n",
            "Epoch - 472, loss - 0.2747418284416199\n",
            "Epoch - 473, loss - 0.2747247815132141\n",
            "Epoch - 474, loss - 0.2747190594673157\n",
            "Epoch - 475, loss - 0.2747122347354889\n",
            "Epoch - 476, loss - 0.2747110426425934\n",
            "Epoch - 477, loss - 0.27470138669013977\n",
            "Epoch - 478, loss - 0.27469685673713684\n",
            "Epoch - 479, loss - 0.27468305826187134\n",
            "Epoch - 480, loss - 0.2746839225292206\n",
            "Epoch - 481, loss - 0.27467969059944153\n",
            "Epoch - 482, loss - 0.274671733379364\n",
            "Epoch - 483, loss - 0.2746647000312805\n",
            "Epoch - 484, loss - 0.27466124296188354\n",
            "Epoch - 485, loss - 0.2746530771255493\n",
            "Epoch - 486, loss - 0.27465319633483887\n",
            "Epoch - 487, loss - 0.27464747428894043\n",
            "Epoch - 488, loss - 0.274642676115036\n",
            "Epoch - 489, loss - 0.27463385462760925\n",
            "Epoch - 490, loss - 0.2746327221393585\n",
            "Epoch - 491, loss - 0.2746310532093048\n",
            "Epoch - 492, loss - 0.274624764919281\n",
            "Epoch - 493, loss - 0.2746211886405945\n",
            "Epoch - 494, loss - 0.27461913228034973\n",
            "Epoch - 495, loss - 0.27461549639701843\n",
            "Epoch - 496, loss - 0.2746122479438782\n",
            "Epoch - 497, loss - 0.274612158536911\n",
            "Epoch - 498, loss - 0.27460458874702454\n",
            "Epoch - 499, loss - 0.2746025621891022\n",
            "Epoch - 500, loss - 0.27459660172462463\n",
            "Epoch - 501, loss - 0.27460041642189026\n",
            "Epoch - 502, loss - 0.27459874749183655\n",
            "Epoch - 503, loss - 0.274594247341156\n",
            "Epoch - 504, loss - 0.27459242939949036\n",
            "Epoch - 505, loss - 0.2745881676673889\n",
            "Epoch - 506, loss - 0.27459225058555603\n",
            "Epoch - 507, loss - 0.2745891809463501\n",
            "Epoch - 508, loss - 0.27458950877189636\n",
            "Epoch - 509, loss - 0.27458181977272034\n",
            "Epoch - 510, loss - 0.27457869052886963\n",
            "Epoch - 511, loss - 0.2745811939239502\n",
            "Epoch - 512, loss - 0.27457451820373535\n",
            "Epoch - 513, loss - 0.27457499504089355\n",
            "Epoch - 514, loss - 0.2745751440525055\n",
            "Epoch - 515, loss - 0.27457132935523987\n",
            "Epoch - 516, loss - 0.2745746374130249\n",
            "Epoch - 517, loss - 0.27456486225128174\n",
            "Epoch - 518, loss - 0.2745651304721832\n",
            "Epoch - 519, loss - 0.2745634913444519\n",
            "Epoch - 520, loss - 0.2745693325996399\n",
            "Epoch - 521, loss - 0.27456459403038025\n",
            "Epoch - 522, loss - 0.27456074953079224\n",
            "Epoch - 523, loss - 0.27456602454185486\n",
            "Epoch - 524, loss - 0.2745591998100281\n",
            "Epoch - 525, loss - 0.2745622396469116\n",
            "Epoch - 526, loss - 0.2745600640773773\n",
            "Epoch - 527, loss - 0.27456045150756836\n",
            "Epoch - 528, loss - 0.27455830574035645\n",
            "Epoch - 529, loss - 0.2745591402053833\n",
            "Epoch - 530, loss - 0.27456191182136536\n",
            "Epoch - 531, loss - 0.2745560109615326\n",
            "Epoch - 532, loss - 0.274552583694458\n",
            "Epoch - 533, loss - 0.27455294132232666\n",
            "Epoch - 534, loss - 0.2745581567287445\n",
            "Epoch - 535, loss - 0.2745569348335266\n",
            "Epoch - 536, loss - 0.27455195784568787\n",
            "Epoch - 537, loss - 0.2745532989501953\n",
            "Epoch - 538, loss - 0.2745523750782013\n",
            "Epoch - 539, loss - 0.27455297112464905\n",
            "Epoch - 540, loss - 0.274551659822464\n",
            "Epoch - 541, loss - 0.2745499908924103\n",
            "Epoch - 542, loss - 0.27455270290374756\n",
            "Epoch - 543, loss - 0.27455127239227295\n",
            "Epoch - 544, loss - 0.2745530605316162\n",
            "Epoch - 545, loss - 0.27455368638038635\n",
            "Epoch - 546, loss - 0.27454674243927\n",
            "Epoch - 547, loss - 0.274549663066864\n",
            "Epoch - 548, loss - 0.2745446264743805\n",
            "Epoch - 549, loss - 0.2745516300201416\n",
            "Epoch - 550, loss - 0.2745461165904999\n",
            "Epoch - 551, loss - 0.27454814314842224\n",
            "Epoch - 552, loss - 0.2745516896247864\n",
            "Epoch - 553, loss - 0.2745446264743805\n",
            "Epoch - 554, loss - 0.27454400062561035\n",
            "Epoch - 555, loss - 0.27454373240470886\n",
            "Epoch - 556, loss - 0.27454283833503723\n",
            "Epoch - 557, loss - 0.27454549074172974\n",
            "Epoch - 558, loss - 0.27454686164855957\n",
            "Epoch - 559, loss - 0.2745461165904999\n",
            "Epoch - 560, loss - 0.2745397686958313\n",
            "Epoch - 561, loss - 0.2745421826839447\n",
            "Epoch - 562, loss - 0.2745426297187805\n",
            "Epoch - 563, loss - 0.27454426884651184\n",
            "Epoch - 564, loss - 0.27454596757888794\n",
            "Epoch - 565, loss - 0.27454349398612976\n",
            "Epoch - 566, loss - 0.27454495429992676\n",
            "Epoch - 567, loss - 0.27454495429992676\n",
            "Epoch - 568, loss - 0.274544358253479\n",
            "Epoch - 569, loss - 0.27454325556755066\n",
            "Epoch - 570, loss - 0.27454352378845215\n",
            "Epoch - 571, loss - 0.2745453715324402\n",
            "Epoch - 572, loss - 0.2745475172996521\n",
            "Epoch - 573, loss - 0.274542897939682\n",
            "Epoch - 574, loss - 0.2745453715324402\n",
            "Epoch - 575, loss - 0.2745400071144104\n",
            "Epoch - 576, loss - 0.274539977312088\n",
            "Epoch - 577, loss - 0.27454257011413574\n",
            "Epoch - 578, loss - 0.2745404541492462\n",
            "Epoch - 579, loss - 0.2745455503463745\n",
            "Epoch - 580, loss - 0.274544894695282\n",
            "Epoch - 581, loss - 0.27454373240470886\n",
            "Epoch - 582, loss - 0.2745451033115387\n",
            "Epoch - 583, loss - 0.2745424807071686\n",
            "Epoch - 584, loss - 0.2745407819747925\n",
            "Epoch - 585, loss - 0.27454084157943726\n",
            "Epoch - 586, loss - 0.27454128861427307\n",
            "Epoch - 587, loss - 0.27454090118408203\n",
            "Epoch - 588, loss - 0.2745412290096283\n",
            "Epoch - 589, loss - 0.27453914284706116\n",
            "Epoch - 590, loss - 0.27454036474227905\n",
            "Epoch - 591, loss - 0.274540513753891\n",
            "Epoch - 592, loss - 0.27454107999801636\n",
            "Epoch - 593, loss - 0.27453890442848206\n",
            "Epoch - 594, loss - 0.27454060316085815\n",
            "Epoch - 595, loss - 0.2745399475097656\n",
            "Epoch - 596, loss - 0.2745436728000641\n",
            "Epoch - 597, loss - 0.27454179525375366\n",
            "Epoch - 598, loss - 0.2745407223701477\n",
            "Epoch - 599, loss - 0.274539977312088\n",
            "Epoch - 600, loss - 0.2745409905910492\n",
            "Epoch - 601, loss - 0.274541437625885\n",
            "Epoch - 602, loss - 0.2745405435562134\n",
            "Epoch - 603, loss - 0.27454087138175964\n",
            "Epoch - 604, loss - 0.2745405435562134\n",
            "Epoch - 605, loss - 0.27454033493995667\n",
            "Epoch - 606, loss - 0.2745440900325775\n",
            "Epoch - 607, loss - 0.27453964948654175\n",
            "Epoch - 608, loss - 0.27453920245170593\n",
            "Epoch - 609, loss - 0.2745394706726074\n",
            "Epoch - 610, loss - 0.2745380699634552\n",
            "Epoch - 611, loss - 0.2745402753353119\n",
            "Epoch - 612, loss - 0.2745383083820343\n",
            "Epoch - 613, loss - 0.2745395600795746\n",
            "Epoch - 614, loss - 0.2745373547077179\n",
            "Epoch - 615, loss - 0.27453744411468506\n",
            "Epoch - 616, loss - 0.27453821897506714\n",
            "Epoch - 617, loss - 0.2745397090911865\n",
            "Epoch - 618, loss - 0.27454203367233276\n",
            "Epoch - 619, loss - 0.2745424509048462\n",
            "Epoch - 620, loss - 0.27454182505607605\n",
            "Epoch - 621, loss - 0.2745417356491089\n",
            "Epoch - 622, loss - 0.2745401859283447\n",
            "Epoch - 623, loss - 0.2745409309864044\n",
            "Epoch - 624, loss - 0.2745395600795746\n",
            "Epoch - 625, loss - 0.274537593126297\n",
            "Epoch - 626, loss - 0.27453771233558655\n",
            "Epoch - 627, loss - 0.2745441198348999\n",
            "Epoch - 628, loss - 0.2745429277420044\n",
            "Epoch - 629, loss - 0.2745438814163208\n",
            "Epoch - 630, loss - 0.27454203367233276\n",
            "Epoch - 631, loss - 0.27454203367233276\n",
            "Epoch - 632, loss - 0.2745426893234253\n",
            "Epoch - 633, loss - 0.2745426893234253\n",
            "Epoch - 634, loss - 0.2745426893234253\n",
            "Epoch - 635, loss - 0.2745426893234253\n",
            "Epoch - 636, loss - 0.2745426893234253\n",
            "Epoch - 637, loss - 0.2745426893234253\n",
            "Epoch - 638, loss - 0.2745426893234253\n",
            "Epoch - 639, loss - 0.2745426893234253\n",
            "Epoch - 640, loss - 0.2745426893234253\n",
            "Epoch - 641, loss - 0.2745426893234253\n",
            "Epoch - 642, loss - 0.2745426893234253\n",
            "Epoch - 643, loss - 0.2745426893234253\n",
            "Epoch - 644, loss - 0.2745426893234253\n",
            "Epoch - 645, loss - 0.2745426893234253\n",
            "Epoch - 646, loss - 0.2745426893234253\n",
            "Epoch - 647, loss - 0.2745426893234253\n",
            "Epoch - 648, loss - 0.2745426893234253\n",
            "Epoch - 649, loss - 0.2745426893234253\n",
            "Epoch - 650, loss - 0.2745426893234253\n",
            "Epoch - 651, loss - 0.2745426893234253\n",
            "Epoch - 652, loss - 0.2745426893234253\n",
            "Epoch - 653, loss - 0.2745426893234253\n",
            "Epoch - 654, loss - 0.2745426893234253\n",
            "Epoch - 655, loss - 0.2745426893234253\n",
            "Epoch - 656, loss - 0.2745426893234253\n",
            "Epoch - 657, loss - 0.2745426893234253\n",
            "Epoch - 658, loss - 0.2745426893234253\n",
            "Epoch - 659, loss - 0.2745426893234253\n",
            "Epoch - 660, loss - 0.2745426893234253\n",
            "Epoch - 661, loss - 0.2745426893234253\n",
            "Epoch - 662, loss - 0.2745426893234253\n",
            "Epoch - 663, loss - 0.2745426893234253\n",
            "Epoch - 664, loss - 0.2745426893234253\n",
            "Epoch - 665, loss - 0.2745426893234253\n",
            "Epoch - 666, loss - 0.2745426893234253\n",
            "Epoch - 667, loss - 0.2745426893234253\n",
            "Epoch - 668, loss - 0.2745426893234253\n",
            "Epoch - 669, loss - 0.2745426893234253\n",
            "Epoch - 670, loss - 0.2745426893234253\n",
            "Epoch - 671, loss - 0.2745426893234253\n",
            "Epoch - 672, loss - 0.2745426893234253\n",
            "Epoch - 673, loss - 0.2745426893234253\n",
            "Epoch - 674, loss - 0.2745426893234253\n",
            "Epoch - 675, loss - 0.2745426893234253\n",
            "Epoch - 676, loss - 0.2745426893234253\n",
            "Epoch - 677, loss - 0.2745426893234253\n",
            "Epoch - 678, loss - 0.2745426893234253\n",
            "Epoch - 679, loss - 0.2745426893234253\n",
            "Epoch - 680, loss - 0.2745426893234253\n",
            "Epoch - 681, loss - 0.2745426893234253\n",
            "Epoch - 682, loss - 0.2745426893234253\n",
            "Epoch - 683, loss - 0.2745426893234253\n",
            "Epoch - 684, loss - 0.2745426893234253\n",
            "Epoch - 685, loss - 0.2745426893234253\n",
            "Epoch - 686, loss - 0.2745426893234253\n",
            "Epoch - 687, loss - 0.2745426893234253\n",
            "Epoch - 688, loss - 0.2745426893234253\n",
            "Epoch - 689, loss - 0.2745426893234253\n",
            "Epoch - 690, loss - 0.2745426893234253\n",
            "Epoch - 691, loss - 0.2745426893234253\n",
            "Epoch - 692, loss - 0.2745426893234253\n",
            "Epoch - 693, loss - 0.2745426893234253\n",
            "Epoch - 694, loss - 0.2745426893234253\n",
            "Epoch - 695, loss - 0.2745426893234253\n",
            "Epoch - 696, loss - 0.2745426893234253\n",
            "Epoch - 697, loss - 0.2745426893234253\n",
            "Epoch - 698, loss - 0.2745426893234253\n",
            "Epoch - 699, loss - 0.2745426893234253\n",
            "Epoch - 700, loss - 0.2745426893234253\n",
            "Epoch - 701, loss - 0.2745426893234253\n",
            "Epoch - 702, loss - 0.2745426893234253\n",
            "Epoch - 703, loss - 0.2745426893234253\n",
            "Epoch - 704, loss - 0.2745426893234253\n",
            "Epoch - 705, loss - 0.2745426893234253\n",
            "Epoch - 706, loss - 0.2745426893234253\n",
            "Epoch - 707, loss - 0.2745426893234253\n",
            "Epoch - 708, loss - 0.2745426893234253\n",
            "Epoch - 709, loss - 0.2745426893234253\n",
            "Epoch - 710, loss - 0.2745426893234253\n",
            "Epoch - 711, loss - 0.2745426893234253\n",
            "Epoch - 712, loss - 0.2745426893234253\n",
            "Epoch - 713, loss - 0.2745426893234253\n",
            "Epoch - 714, loss - 0.2745426893234253\n",
            "Epoch - 715, loss - 0.2745426893234253\n",
            "Epoch - 716, loss - 0.2745426893234253\n",
            "Epoch - 717, loss - 0.2745426893234253\n",
            "Epoch - 718, loss - 0.2745426893234253\n",
            "Epoch - 719, loss - 0.2745426893234253\n",
            "Epoch - 720, loss - 0.2745426893234253\n",
            "Epoch - 721, loss - 0.2745426893234253\n",
            "Epoch - 722, loss - 0.2745426893234253\n",
            "Epoch - 723, loss - 0.2745426893234253\n",
            "Epoch - 724, loss - 0.2745426893234253\n",
            "Epoch - 725, loss - 0.2745426893234253\n",
            "Epoch - 726, loss - 0.2745426893234253\n",
            "Epoch - 727, loss - 0.2745426893234253\n",
            "Epoch - 728, loss - 0.2745426893234253\n",
            "Epoch - 729, loss - 0.2745426893234253\n",
            "Epoch - 730, loss - 0.2745426893234253\n",
            "Epoch - 731, loss - 0.2745426893234253\n",
            "Epoch - 732, loss - 0.2745426893234253\n",
            "Epoch - 733, loss - 0.2745426893234253\n",
            "Epoch - 734, loss - 0.2745426893234253\n",
            "Epoch - 735, loss - 0.2745426893234253\n",
            "Epoch - 736, loss - 0.2745426893234253\n",
            "Epoch - 737, loss - 0.2745426893234253\n",
            "Epoch - 738, loss - 0.2745426893234253\n",
            "Epoch - 739, loss - 0.2745426893234253\n",
            "Epoch - 740, loss - 0.2745426893234253\n",
            "Epoch - 741, loss - 0.2745426893234253\n",
            "Epoch - 742, loss - 0.2745426893234253\n",
            "Epoch - 743, loss - 0.2745426893234253\n",
            "Epoch - 744, loss - 0.2745426893234253\n",
            "Epoch - 745, loss - 0.2745426893234253\n",
            "Epoch - 746, loss - 0.2745426893234253\n",
            "Epoch - 747, loss - 0.2745426893234253\n",
            "Epoch - 748, loss - 0.2745426893234253\n",
            "Epoch - 749, loss - 0.2745426893234253\n",
            "Epoch - 750, loss - 0.2745426893234253\n",
            "Epoch - 751, loss - 0.2745426893234253\n",
            "Epoch - 752, loss - 0.2745426893234253\n",
            "Epoch - 753, loss - 0.2745426893234253\n",
            "Epoch - 754, loss - 0.2745426893234253\n",
            "Epoch - 755, loss - 0.2745426893234253\n",
            "Epoch - 756, loss - 0.2745426893234253\n",
            "Epoch - 757, loss - 0.2745426893234253\n",
            "Epoch - 758, loss - 0.2745426893234253\n",
            "Epoch - 759, loss - 0.2745426893234253\n",
            "Epoch - 760, loss - 0.2745426893234253\n",
            "Epoch - 761, loss - 0.2745426893234253\n",
            "Epoch - 762, loss - 0.2745426893234253\n",
            "Epoch - 763, loss - 0.2745426893234253\n",
            "Epoch - 764, loss - 0.2745426893234253\n",
            "Epoch - 765, loss - 0.2745426893234253\n",
            "Epoch - 766, loss - 0.2745426893234253\n",
            "Epoch - 767, loss - 0.2745426893234253\n",
            "Epoch - 768, loss - 0.2745426893234253\n",
            "Epoch - 769, loss - 0.2745426893234253\n",
            "Epoch - 770, loss - 0.2745426893234253\n",
            "Epoch - 771, loss - 0.2745426893234253\n",
            "Epoch - 772, loss - 0.2745426893234253\n",
            "Epoch - 773, loss - 0.2745426893234253\n",
            "Epoch - 774, loss - 0.2745426893234253\n",
            "Epoch - 775, loss - 0.2745426893234253\n",
            "Epoch - 776, loss - 0.2745426893234253\n",
            "Epoch - 777, loss - 0.2745426893234253\n",
            "Epoch - 778, loss - 0.2745426893234253\n",
            "Epoch - 779, loss - 0.2745426893234253\n",
            "Epoch - 780, loss - 0.2745426893234253\n",
            "Epoch - 781, loss - 0.2745426893234253\n",
            "Epoch - 782, loss - 0.2745426893234253\n",
            "Epoch - 783, loss - 0.2745426893234253\n",
            "Epoch - 784, loss - 0.2745426893234253\n",
            "Epoch - 785, loss - 0.2745426893234253\n",
            "Epoch - 786, loss - 0.2745426893234253\n",
            "Epoch - 787, loss - 0.2745426893234253\n",
            "Epoch - 788, loss - 0.2745426893234253\n",
            "Epoch - 789, loss - 0.2745426893234253\n",
            "Epoch - 790, loss - 0.2745426893234253\n",
            "Epoch - 791, loss - 0.2745426893234253\n",
            "Epoch - 792, loss - 0.2745426893234253\n",
            "Epoch - 793, loss - 0.2745426893234253\n",
            "Epoch - 794, loss - 0.2745426893234253\n",
            "Epoch - 795, loss - 0.2745426893234253\n",
            "Epoch - 796, loss - 0.2745426893234253\n",
            "Epoch - 797, loss - 0.2745426893234253\n",
            "Epoch - 798, loss - 0.2745426893234253\n",
            "Epoch - 799, loss - 0.2745426893234253\n",
            "Epoch - 800, loss - 0.2745426893234253\n",
            "Epoch - 801, loss - 0.2745426893234253\n",
            "Epoch - 802, loss - 0.2745426893234253\n",
            "Epoch - 803, loss - 0.2745426893234253\n",
            "Epoch - 804, loss - 0.2745426893234253\n",
            "Epoch - 805, loss - 0.2745426893234253\n",
            "Epoch - 806, loss - 0.2745426893234253\n",
            "Epoch - 807, loss - 0.2745426893234253\n",
            "Epoch - 808, loss - 0.2745426893234253\n",
            "Epoch - 809, loss - 0.2745426893234253\n",
            "Epoch - 810, loss - 0.2745426893234253\n",
            "Epoch - 811, loss - 0.2745426893234253\n",
            "Epoch - 812, loss - 0.2745426893234253\n",
            "Epoch - 813, loss - 0.2745426893234253\n",
            "Epoch - 814, loss - 0.2745426893234253\n",
            "Epoch - 815, loss - 0.2745426893234253\n",
            "Epoch - 816, loss - 0.2745426893234253\n",
            "Epoch - 817, loss - 0.2745426893234253\n",
            "Epoch - 818, loss - 0.2745426893234253\n",
            "Epoch - 819, loss - 0.2745426893234253\n",
            "Epoch - 820, loss - 0.2745426893234253\n",
            "Epoch - 821, loss - 0.2745426893234253\n",
            "Epoch - 822, loss - 0.2745426893234253\n",
            "Epoch - 823, loss - 0.2745426893234253\n",
            "Epoch - 824, loss - 0.2745426893234253\n",
            "Epoch - 825, loss - 0.2745426893234253\n",
            "Epoch - 826, loss - 0.2745426893234253\n",
            "Epoch - 827, loss - 0.2745426893234253\n",
            "Epoch - 828, loss - 0.2745426893234253\n",
            "Epoch - 829, loss - 0.2745426893234253\n",
            "Epoch - 830, loss - 0.2745426893234253\n",
            "Epoch - 831, loss - 0.2745426893234253\n",
            "Epoch - 832, loss - 0.2745426893234253\n",
            "Epoch - 833, loss - 0.2745426893234253\n",
            "Epoch - 834, loss - 0.2745426893234253\n",
            "Epoch - 835, loss - 0.2745426893234253\n",
            "Epoch - 836, loss - 0.2745426893234253\n",
            "Epoch - 837, loss - 0.2745426893234253\n",
            "Epoch - 838, loss - 0.2745426893234253\n",
            "Epoch - 839, loss - 0.2745426893234253\n",
            "Epoch - 840, loss - 0.2745426893234253\n",
            "Epoch - 841, loss - 0.2745426893234253\n",
            "Epoch - 842, loss - 0.2745426893234253\n",
            "Epoch - 843, loss - 0.2745426893234253\n",
            "Epoch - 844, loss - 0.2745426893234253\n",
            "Epoch - 845, loss - 0.2745426893234253\n",
            "Epoch - 846, loss - 0.2745426893234253\n",
            "Epoch - 847, loss - 0.2745426893234253\n",
            "Epoch - 848, loss - 0.2745426893234253\n",
            "Epoch - 849, loss - 0.2745426893234253\n",
            "Epoch - 850, loss - 0.2745426893234253\n",
            "Epoch - 851, loss - 0.2745426893234253\n",
            "Epoch - 852, loss - 0.2745426893234253\n",
            "Epoch - 853, loss - 0.2745426893234253\n",
            "Epoch - 854, loss - 0.2745426893234253\n",
            "Epoch - 855, loss - 0.2745426893234253\n",
            "Epoch - 856, loss - 0.2745426893234253\n",
            "Epoch - 857, loss - 0.2745426893234253\n",
            "Epoch - 858, loss - 0.2745426893234253\n",
            "Epoch - 859, loss - 0.2745426893234253\n",
            "Epoch - 860, loss - 0.2745426893234253\n",
            "Epoch - 861, loss - 0.2745426893234253\n",
            "Epoch - 862, loss - 0.2745426893234253\n",
            "Epoch - 863, loss - 0.2745426893234253\n",
            "Epoch - 864, loss - 0.2745426893234253\n",
            "Epoch - 865, loss - 0.2745426893234253\n",
            "Epoch - 866, loss - 0.2745426893234253\n",
            "Epoch - 867, loss - 0.2745426893234253\n",
            "Epoch - 868, loss - 0.2745426893234253\n",
            "Epoch - 869, loss - 0.2745426893234253\n",
            "Epoch - 870, loss - 0.2745426893234253\n",
            "Epoch - 871, loss - 0.2745426893234253\n",
            "Epoch - 872, loss - 0.2745426893234253\n",
            "Epoch - 873, loss - 0.2745426893234253\n",
            "Epoch - 874, loss - 0.2745426893234253\n",
            "Epoch - 875, loss - 0.2745426893234253\n",
            "Epoch - 876, loss - 0.2745426893234253\n",
            "Epoch - 877, loss - 0.2745426893234253\n",
            "Epoch - 878, loss - 0.2745426893234253\n",
            "Epoch - 879, loss - 0.2745426893234253\n",
            "Epoch - 880, loss - 0.2745426893234253\n",
            "Epoch - 881, loss - 0.2745426893234253\n",
            "Epoch - 882, loss - 0.2745426893234253\n",
            "Epoch - 883, loss - 0.2745426893234253\n",
            "Epoch - 884, loss - 0.2745426893234253\n",
            "Epoch - 885, loss - 0.2745426893234253\n",
            "Epoch - 886, loss - 0.2745426893234253\n",
            "Epoch - 887, loss - 0.2745426893234253\n",
            "Epoch - 888, loss - 0.2745426893234253\n",
            "Epoch - 889, loss - 0.2745426893234253\n",
            "Epoch - 890, loss - 0.2745426893234253\n",
            "Epoch - 891, loss - 0.2745426893234253\n",
            "Epoch - 892, loss - 0.2745426893234253\n",
            "Epoch - 893, loss - 0.2745426893234253\n",
            "Epoch - 894, loss - 0.2745426893234253\n",
            "Epoch - 895, loss - 0.2745426893234253\n",
            "Epoch - 896, loss - 0.2745426893234253\n",
            "Epoch - 897, loss - 0.2745426893234253\n",
            "Epoch - 898, loss - 0.2745426893234253\n",
            "Epoch - 899, loss - 0.2745426893234253\n",
            "Epoch - 900, loss - 0.2745426893234253\n",
            "Epoch - 901, loss - 0.2745426893234253\n",
            "Epoch - 902, loss - 0.2745426893234253\n",
            "Epoch - 903, loss - 0.2745426893234253\n",
            "Epoch - 904, loss - 0.2745426893234253\n",
            "Epoch - 905, loss - 0.2745426893234253\n",
            "Epoch - 906, loss - 0.2745426893234253\n",
            "Epoch - 907, loss - 0.2745426893234253\n",
            "Epoch - 908, loss - 0.2745426893234253\n",
            "Epoch - 909, loss - 0.2745426893234253\n",
            "Epoch - 910, loss - 0.2745426893234253\n",
            "Epoch - 911, loss - 0.2745426893234253\n",
            "Epoch - 912, loss - 0.2745426893234253\n",
            "Epoch - 913, loss - 0.2745426893234253\n",
            "Epoch - 914, loss - 0.2745426893234253\n",
            "Epoch - 915, loss - 0.2745426893234253\n",
            "Epoch - 916, loss - 0.2745426893234253\n",
            "Epoch - 917, loss - 0.2745426893234253\n",
            "Epoch - 918, loss - 0.2745426893234253\n",
            "Epoch - 919, loss - 0.2745426893234253\n",
            "Epoch - 920, loss - 0.2745426893234253\n",
            "Epoch - 921, loss - 0.2745426893234253\n",
            "Epoch - 922, loss - 0.2745426893234253\n",
            "Epoch - 923, loss - 0.2745426893234253\n",
            "Epoch - 924, loss - 0.2745426893234253\n",
            "Epoch - 925, loss - 0.2745426893234253\n",
            "Epoch - 926, loss - 0.2745426893234253\n",
            "Epoch - 927, loss - 0.2745426893234253\n",
            "Epoch - 928, loss - 0.2745426893234253\n",
            "Epoch - 929, loss - 0.2745426893234253\n",
            "Epoch - 930, loss - 0.2745426893234253\n",
            "Epoch - 931, loss - 0.2745426893234253\n",
            "Epoch - 932, loss - 0.2745426893234253\n",
            "Epoch - 933, loss - 0.2745426893234253\n",
            "Epoch - 934, loss - 0.2745426893234253\n",
            "Epoch - 935, loss - 0.2745426893234253\n",
            "Epoch - 936, loss - 0.2745426893234253\n",
            "Epoch - 937, loss - 0.2745426893234253\n",
            "Epoch - 938, loss - 0.2745426893234253\n",
            "Epoch - 939, loss - 0.2745426893234253\n",
            "Epoch - 940, loss - 0.2745426893234253\n",
            "Epoch - 941, loss - 0.2745426893234253\n",
            "Epoch - 942, loss - 0.2745426893234253\n",
            "Epoch - 943, loss - 0.2745426893234253\n",
            "Epoch - 944, loss - 0.2745426893234253\n",
            "Epoch - 945, loss - 0.2745426893234253\n",
            "Epoch - 946, loss - 0.2745426893234253\n",
            "Epoch - 947, loss - 0.2745426893234253\n",
            "Epoch - 948, loss - 0.2745426893234253\n",
            "Epoch - 949, loss - 0.2745426893234253\n",
            "Epoch - 950, loss - 0.2745426893234253\n",
            "Epoch - 951, loss - 0.2745426893234253\n",
            "Epoch - 952, loss - 0.2745426893234253\n",
            "Epoch - 953, loss - 0.2745426893234253\n",
            "Epoch - 954, loss - 0.2745426893234253\n",
            "Epoch - 955, loss - 0.2745426893234253\n",
            "Epoch - 956, loss - 0.2745426893234253\n",
            "Epoch - 957, loss - 0.2745426893234253\n",
            "Epoch - 958, loss - 0.2745426893234253\n",
            "Epoch - 959, loss - 0.2745426893234253\n",
            "Epoch - 960, loss - 0.2745426893234253\n",
            "Epoch - 961, loss - 0.2745426893234253\n",
            "Epoch - 962, loss - 0.2745426893234253\n",
            "Epoch - 963, loss - 0.2745426893234253\n",
            "Epoch - 964, loss - 0.2745426893234253\n",
            "Epoch - 965, loss - 0.2745426893234253\n",
            "Epoch - 966, loss - 0.2745426893234253\n",
            "Epoch - 967, loss - 0.2745426893234253\n",
            "Epoch - 968, loss - 0.2745426893234253\n",
            "Epoch - 969, loss - 0.2745426893234253\n",
            "Epoch - 970, loss - 0.2745426893234253\n",
            "Epoch - 971, loss - 0.2745426893234253\n",
            "Epoch - 972, loss - 0.2745426893234253\n",
            "Epoch - 973, loss - 0.2745426893234253\n",
            "Epoch - 974, loss - 0.2745426893234253\n",
            "Epoch - 975, loss - 0.2745426893234253\n",
            "Epoch - 976, loss - 0.2745426893234253\n",
            "Epoch - 977, loss - 0.2745426893234253\n",
            "Epoch - 978, loss - 0.2745426893234253\n",
            "Epoch - 979, loss - 0.2745426893234253\n",
            "Epoch - 980, loss - 0.2745426893234253\n",
            "Epoch - 981, loss - 0.2745426893234253\n",
            "Epoch - 982, loss - 0.2745426893234253\n",
            "Epoch - 983, loss - 0.2745426893234253\n",
            "Epoch - 984, loss - 0.2745426893234253\n",
            "Epoch - 985, loss - 0.2745426893234253\n",
            "Epoch - 986, loss - 0.2745426893234253\n",
            "Epoch - 987, loss - 0.2745426893234253\n",
            "Epoch - 988, loss - 0.2745426893234253\n",
            "Epoch - 989, loss - 0.2745426893234253\n",
            "Epoch - 990, loss - 0.2745426893234253\n",
            "Epoch - 991, loss - 0.2745426893234253\n",
            "Epoch - 992, loss - 0.2745426893234253\n",
            "Epoch - 993, loss - 0.2745426893234253\n",
            "Epoch - 994, loss - 0.2745426893234253\n",
            "Epoch - 995, loss - 0.2745426893234253\n",
            "Epoch - 996, loss - 0.2745426893234253\n",
            "Epoch - 997, loss - 0.2745426893234253\n",
            "Epoch - 998, loss - 0.2745426893234253\n",
            "Epoch - 999, loss - 0.2745426893234253\n",
            "Epoch - 1000, loss - 0.2745426893234253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Br8cimG-Sqj",
        "outputId": "ce8ec4b7-a7bc-47d6-f66a-0ecd23a2d656"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[176.0548],\n",
              "        [352.5266],\n",
              "        [497.5968]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISA-Q964-Sn6",
        "outputId": "ef98c8ab-2a44-4ce3-b4d0-4b240a5c1002"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([31.6278], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-bBwvFr-SlO",
        "outputId": "4c2bde80-47fc-4554-f2c8-8bc97578eba8"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_t * std.reshape(-1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAXVM5ji-Sik",
        "outputId": "d466275b-62d6-48e4-9c92-cb1e8685330a"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[176.0001],\n",
              "        [352.5093],\n",
              "        [497.6636]])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fndzEVGV-Sf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gnk_Psxq-SdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExtUVffv-SbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYDtKNny-SYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2ZBN3XF-SWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}